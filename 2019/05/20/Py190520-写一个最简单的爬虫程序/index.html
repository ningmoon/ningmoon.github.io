<!DOCTYPE html>
<html lang="en">

<!-- Head tag -->
<head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">
    <meta name="google-site-verification" content="xBT4GhYoi5qRD5tr338pgPM5OWHHIDR6mNg1a3euekI" />
    <meta name="baidu-site-verification" content="093lY4ziMu" />
    <meta name="viewport" content="width=device-width, initial-scale=1, user-scalable=no">
    <meta name="description" content="Done is better than perfect">
    <meta name="keyword"  content="zhihao, brand new blog">
    <link rel="shortcut icon" href="/img/favicon.ico">
    <!-- This is the logo of your website -->
    <!-- Place this tag in your head or just before your close body tag -->
    <script async defer src="https://buttons.github.io/buttons.js"></script>
    <!--<link href='http://fonts.googleapis.com/css?family=Montserrat:400,700' rel='stylesheet' type='text/css'>-->
    <title>
        
          写一个最简单的爬虫程序 - Zhihao&#39;s Blog
        
    </title>

    <link rel="canonical" href="http://ningmoon.github.io/2019/05/20/Py190520-写一个最简单的爬虫程序/">

    <!-- Bootstrap Core CSS -->
    
<link rel="stylesheet" href="/css/bootstrap.min.css">


    <!-- Custom CSS --> 
    
        
<link rel="stylesheet" href="/css/dusign-light.css">

        
<link rel="stylesheet" href="/css/dusign-common-light.css">

        
<link rel="stylesheet" href="/css/font-awesome.css">

        
<link rel="stylesheet" href="/css/toc.css">

        <!-- background effects end -->
    
    
    <!-- Pygments Highlight CSS -->
    
<link rel="stylesheet" href="/css/highlight.css">


    
<link rel="stylesheet" href="/css/widget.css">


    
<link rel="stylesheet" href="/css/rocket.css">


    
<link rel="stylesheet" href="/css/signature.css">


    
<link rel="stylesheet" href="/css/fonts.googleapis.css">


    <link rel="stylesheet" href="//cdn.bootcss.com/font-awesome/4.3.0/css/font-awesome.min.css">

    <!-- photography -->
    
<link rel="stylesheet" href="/css/photography.css">


    <!-- ga & ba script hoook -->
    <script></script>
<meta name="generator" content="Hexo 4.2.1"></head>


<!-- hack iOS CSS :active style -->
<body ontouchstart="">

    <!-- background effects start -->
    
    <!-- background effects end -->

	<!-- Modified by Yu-Hsuan Yen -->
<!-- Post Header -->
<style type="text/css">
    header.intro-header{
        
            
                background-image: linear-gradient(rgba(0, 0, 0, 0.3), rgba(0, 0, 0, 0.3)), url('python-bg.jpg')
                /*post*/
            
        
    }
    
    #signature{
        background-image: url('/img/signature/zhihao.png');
    }
    
</style>

<header class="intro-header" >
    <!-- Signature -->
    <div id="signature">
        <div class="container">
            <div class="row">
                <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                
                    <div class="post-heading">
                        <div class="tags">
                            
                              <a class="tag" href="/tags/#Python" title="Python">Python</a>
                            
                              <a class="tag" href="/tags/#Web Crawler" title="Web Crawler">Web Crawler</a>
                            
                        </div>
                        <h1>写一个最简单的爬虫程序</h1>
                        <h2 class="subheading">Write the simplest crawler program</h2>
                        <span class="meta">
                            Posted by Zhihao on
                            2019-05-20
                        </span>

                        

                    </div>
                

                </div>
            </div>
        </div>      
    </div>

    
    <div class="waveWrapper">
        <div class="wave wave_before" style="background-image: url('/img/wave-light.png')"></div>
        <div class="wave wave_after" style="background-image: url('/img/wave-light.png')"></div>
    </div>
    
</header>

	
    <!-- Navigation -->
<nav class="navbar navbar-default navbar-custom navbar-fixed-top">
    <div class="container-fluid">
        <!-- Brand and toggle get grouped for better mobile display -->
        <div class="navbar-header page-scroll">
            <button type="button" class="navbar-toggle">
                <span class="sr-only">Toggle navigation</span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
                <span class="icon-bar"></span>
            </button>
            <a class="navbar-brand" href="/">Zhihao&#39;s Blog</a>
        </div>

        <!-- Collect the nav links, forms, and other content for toggling -->
        <!-- Known Issue, found by Hux:
            <nav>'s height woule be hold on by its content.
            so, when navbar scale out, the <nav> will cover tags.
            also mask any touch event of tags, unfortunately.
        -->
        <div id="huxblog_navbar">
            <div class="navbar-collapse">
                <ul class="nav navbar-nav navbar-right">
                    <li>
                        <a href="/">Home</a>
                        <!-- 这是原代码<a href="/">Home</a> -->
                    </li>

                    

                        
                        
                    

                        
                        <li>
                            <a href="/archive/">Archives</a>
                        </li>
                        
                        
                    

                        
                        <li>
                            <a href="/categories/">Categories</a>
                        </li>
                        
                        
                    

                        
                        <li>
                            <a href="/csdn/">csdn</a>
                        </li>
                        
                        
                    

                        
                        <li>
                            <a href="/resume/">Resume</a>
                        </li>
                        
                        
                    
                    
                    
                    <li>
                        <a href="https://blog.csdn.net/ningmoon" target="_blank">Blog</a>
                        <!-- <a href="/">Home</a> -->
                        <!-- target="_blank"新开标签页 href="https://blog.csdn.net/ningmoon"实现跳转新地址 config.root默认地址跳转-->
                        <!-- 这是原代码<a href="https://blog.csdn.net/ningmoon" target="_blank">Chinese Blog</a> -->
                    </li>
                    
                </ul>
            </div>
        </div>
        <!-- /.navbar-collapse -->
    </div>
    <!-- /.container -->
</nav>
<script>
    // Drop Bootstarp low-performance Navbar
    // Use customize navbar with high-quality material design animation
    // in high-perf jank-free CSS3 implementation
    var $body   = document.body;
    var $toggle = document.querySelector('.navbar-toggle');
    var $navbar = document.querySelector('#huxblog_navbar');
    var $collapse = document.querySelector('.navbar-collapse');

    $toggle.addEventListener('click', handleMagic)
    function handleMagic(e){
        if ($navbar.className.indexOf('in') > 0) {
        // CLOSE
            $navbar.className = " ";
            // wait until animation end.
            setTimeout(function(){
                // prevent frequently toggle
                if($navbar.className.indexOf('in') < 0) {
                    $collapse.style.height = "0px"
                }
            },400)
        }else{
        // OPEN
            $collapse.style.height = "auto"
            $navbar.className += " in";
        }
    }
</script>


    <!-- Main Content -->
    <!-- Post Content -->
<article>
    <div class="container">
        <div class="row">

            <!-- Post Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                post-container">

                <p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-1.png" alt="The First Title Picture"></p>
<a id="more"></a>
<p><strong>本文将介绍如何写一个最简单的Python爬虫程序</strong></p>
<p>主要分为以下 5 部分内容：</p>
<ol>
<li>了解网页基础；</li>
<li>使用 requests 库抓取网站数据；</li>
<li>使用 Beautiful Soup 解析网页；</li>
<li>清洗和组织数据；</li>
<li>爬虫攻防战；</li>
</ol>
<h1 id="1-网页基础"><a href="#1-网页基础" class="headerlink" title="1 网页基础"></a>1 网页基础</h1><h2 id="1-1-网页结构"><a href="#1-1-网页结构" class="headerlink" title="1.1 网页结构"></a>1.1 网页结构</h2><p>网页一般由三部分组成，分别是 <code>HTML</code>（超文本标记语言）、<code>CSS</code>（层叠样式表）和 <code>JScript</code>（活动脚本语言）。</p>
<p><strong>HTML</strong></p>
<p><code>HTML</code>是整个网页的结构，相当于整个网站的框架。带<code>“＜”和“＞”</code>符号的都是属于<code>HTML</code>的标签，并且标签都是成对出现的。</p>
<p>常见的标签如下：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span>..<span class="tag">&lt;/<span class="name">html</span>&gt;</span> 表示标记中间的元素是网页</span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span>..<span class="tag">&lt;/<span class="name">body</span>&gt;</span> 表示用户可见的内容</span><br><span class="line"><span class="tag">&lt;<span class="name">div</span>&gt;</span>..<span class="tag">&lt;/<span class="name">div</span>&gt;</span> 表示框架</span><br><span class="line"><span class="tag">&lt;<span class="name">p</span>&gt;</span>..<span class="tag">&lt;/<span class="name">p</span>&gt;</span> 表示段落</span><br><span class="line"><span class="tag">&lt;<span class="name">li</span>&gt;</span>..<span class="tag">&lt;/<span class="name">li</span>&gt;</span>表示列表</span><br><span class="line"><span class="tag">&lt;<span class="name">img</span>&gt;</span>..<span class="tag">&lt;/<span class="name">img</span>&gt;</span>表示图片</span><br><span class="line"><span class="tag">&lt;<span class="name">h1</span>&gt;</span>..<span class="tag">&lt;/<span class="name">h1</span>&gt;</span>表示标题</span><br><span class="line"><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">""</span>&gt;</span>..<span class="tag">&lt;/<span class="name">a</span>&gt;</span>表示超链接</span><br></pre></td></tr></table></figure>
<p><strong>CSS</strong></p>
<p><code>CSS</code> 表示样式，比如标签中的<code>＜style type=＂text/css＂＞</code>表示下面引用一个 <code>CSS</code>，在 <code>CSS</code>中定义了外观。</p>
<p><strong>JScript</strong></p>
<p><code>JScript</code>表示功能。交互的内容和各种特效都在<code>JScript</code>中，<code>JScript</code> 描述了网站中的各种功能。</p>
<p>如果用人体来比喻，<code>HTML</code> 是人的骨架，并且定义了人的嘴巴、眼睛、耳朵等要长在哪里。<code>CSS</code> 是人的外观细节，如嘴巴长什么样子，眼睛是双眼皮还是单眼皮，是大眼睛还是小眼睛，皮肤是黑色的还是白色的等。<code>JScript</code> 表示人的技能，例如跳舞、唱歌或者演奏乐器等。</p>
<h2 id="1-2-写一个简单的-HTML"><a href="#1-2-写一个简单的-HTML" class="headerlink" title="1.2 写一个简单的 HTML"></a>1.2 写一个简单的 HTML</h2><p>通过编写和修改<code>HTML</code>，可以更好地理解<code>HTML</code>。首先打开一个记事本，然后输入下面的内容：</p>
<figure class="highlight html"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br></pre></td><td class="code"><pre><span class="line"><span class="tag">&lt;<span class="name">html</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">head</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">title</span>&gt;</span> Python 3 爬虫与数据清洗入门与实战<span class="tag">&lt;/<span class="name">title</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">head</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;<span class="name">body</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">p</span>&gt;</span>Python 3爬虫与数据清洗入门与实战<span class="tag">&lt;/<span class="name">p</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;<span class="name">div</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;<span class="name">ul</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span><span class="tag">&lt;<span class="name">a</span> <span class="attr">href</span>=<span class="string">"http://c.biancheng.net"</span>&gt;</span>爬虫<span class="tag">&lt;/<span class="name">a</span>&gt;</span><span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">            <span class="tag">&lt;<span class="name">li</span>&gt;</span>数据清洗<span class="tag">&lt;/<span class="name">li</span>&gt;</span></span><br><span class="line">        <span class="tag">&lt;/<span class="name">ul</span>&gt;</span></span><br><span class="line">    <span class="tag">&lt;/<span class="name">div</span>&gt;</span></span><br><span class="line"><span class="tag">&lt;/<span class="name">body</span>&gt;</span></span><br></pre></td></tr></table></figure>
<p>输入代码后，保存记事本，然后修改文件名和后缀名为”HTML.html”；</p>
<p>用浏览器打开后的效果，如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-2.gif" alt="The First Title Picture"></p>
<p>这段代码只是用到了 <code>HTML</code>，读者可以自行修改代码中的中文，然后观察其变化。</p>
<h2 id="1-3-关于爬虫的合法性"><a href="#1-3-关于爬虫的合法性" class="headerlink" title="1.3 关于爬虫的合法性"></a>1.3 关于爬虫的合法性</h2><p>几乎每一个网站都有一个名为 <code>robots.txt</code> 的文档，当然也有部分网站没有设定 <code>robots.txt</code>。对于没有设定 <code>robots.txt</code> 的网站可以通过网络爬虫获取没有口令加密的数据，也就是该网站所有页面数据都可以爬取。如果网站有 <code>robots.txt</code> 文档，就要判断是否有禁止访客获取的数据。</p>
<p>以淘宝网为例，在浏览器中访问 <a href="https://www.taobao.com/robots.txt，如下图所示：" target="_blank" rel="noopener">https://www.taobao.com/robots.txt，如下图所示：</a></p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-3.gif" alt="The First Title Picture"></p>
<p>淘宝网允许部分爬虫访问它的部分路径，而对于没有得到允许的用户，则全部禁止爬取，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">User-Agent:*</span><br><span class="line">Disallow:&#x2F;</span><br></pre></td></tr></table></figure>
<p>这一句代码的意思是除前面指定的爬虫外，不允许其他爬虫爬取任何数据。</p>
<h1 id="2-使用-requests-库请求网站"><a href="#2-使用-requests-库请求网站" class="headerlink" title="2 使用 requests 库请求网站"></a>2 使用 requests 库请求网站</h1><h2 id="2-1-安装-requests-库"><a href="#2-1-安装-requests-库" class="headerlink" title="2.1 安装 requests 库"></a>2.1 安装 requests 库</h2><p>终端输入命令<code>pip install requests</code>，就可以开始安装了。</p>
<h2 id="2-2-爬虫的基本原理"><a href="#2-2-爬虫的基本原理" class="headerlink" title="2.2 爬虫的基本原理"></a>2.2 爬虫的基本原理</h2><p>网页请求的过程分为两个环节：</p>
<ol>
<li><p>Request （请求）：每一个展示在用户面前的网页都必须经过这一步，也就是向服务器发送访问请求。</p>
</li>
<li><p>Response（响应）：服务器在接收到用户的请求后，会验证请求的有效性，然后向用户（客户端）发送响应的内容，客户端接收服务器响应的内容，将内容展示出来，就是我们所熟悉的网页请求，如下图所示。</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-4.gif" alt="The First Title Picture"></p>
</li>
</ol>
<p>网页请求的方式也分为两种：</p>
<ol>
<li>GET：最常见的方式，一般用于获取或者查询资源信息，也是大多数网站使用的方式，响应速度快。</li>
<li>POST：相比 GET 方式，多了以表单形式上传参数的功能，因此除查询信息外，还可以修改信息。</li>
</ol>
<p><span style="color:red;"><strong>所以，在写爬虫前要先确定网页请求的方式是什么。</strong></span></p>
<h2 id="2-3-网页请求方式一：使用-GET-方式抓取数据"><a href="#2-3-网页请求方式一：使用-GET-方式抓取数据" class="headerlink" title="2.3 网页请求方式一：使用 GET 方式抓取数据"></a>2.3 网页请求方式一：使用 GET 方式抓取数据</h2><p>随意打开一个网站，比如下图所示的某瓣，在源码中【Ctrl+F】搜索页面出现的字词，比如“正在热映”四个字，如果能在源码中直接搜索到，那么这个网站的请求方式就是<code>GET</code>。如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-5.png" alt="The First Title Picture"></p>
<p>确定好请求对象和方式后，输入以下代码：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests                    <span class="comment">#导入requests包</span></span><br><span class="line">url = <span class="string">'http://www.cntour.cn/'</span></span><br><span class="line">strhtml = requests.get(url)        <span class="comment">#Get方式获取网页数据</span></span><br><span class="line">print(strhtml.text)</span><br></pre></td></tr></table></figure>
<p>如果成功的话，你已经看到<code>strhtml.text</code>打印的结果。</p>
<p>接下来简单介绍一下上面几行代码的意思：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">import requests  #加载库使用的语句是 import+库的名字</span><br></pre></td></tr></table></figure>
<p>用 <code>GET</code> 方式获取数据需要调用 <code>requests</code> 库中的 <code>get</code> 方法，使用方法是在 <code>requests</code> 后输入英文点号，如下所示：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">requests.get</span><br></pre></td></tr></table></figure>
<p>将获取到的数据存到 <code>strhtml</code> 变量中，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strhtml &#x3D; request.get(url)</span><br></pre></td></tr></table></figure>
<p>这个时候 <code>strhtml</code> 是一个 <code>URL</code> 对象，它代表整个网页，但此时只需要网页中的源码，下面的语句表示网页源码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">strhtml.text</span><br></pre></td></tr></table></figure>
<h2 id="2-4-网页请求方式二：使用-POST-方式抓取数据"><a href="#2-4-网页请求方式二：使用-POST-方式抓取数据" class="headerlink" title="2.4 网页请求方式二：使用 POST 方式抓取数据"></a>2.4 网页请求方式二：使用 POST 方式抓取数据</h2><p>首先输入有道翻译的网址：<a href="http://fanyi.youdao.com/，进入有道翻译页面。" target="_blank" rel="noopener">http://fanyi.youdao.com/，进入有道翻译页面。</a><br>按快捷键 F12，进入开发者模式，单击 <code>Network</code>，此时内容为空，如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-6.gif" alt="The First Title Picture"></p>
<p>在有道翻译中输入“我爱中国”，单击“翻译”按钮，如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-7.gif" alt="The First Title Picture"></p>
<p>在开发者模式中，依次单击<code>Network</code>按钮和<code>XHR</code>按钮，找到翻译数据，如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-8.gif" alt="The First Title Picture"></p>
<p>单击 <code>Headers</code>，发现请求数据的方式为 <code>POST</code>。如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-9.gif" alt="The First Title Picture"></p>
<p>找到数据所在之处并且明确请求方式之后，接下来开始撰写爬虫。<br>首先，将 <code>Headers</code> 中的 <code>URL</code> 复制出来，并赋值给 <code>url</code>，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">url &#x3D; &#39;http:&#x2F;&#x2F;fanyi.youdao.com&#x2F;translate_o?smartresult&#x3D;dict&amp;smartresult&#x3D;rule&#39;</span><br></pre></td></tr></table></figure>
<p><code>POST</code> 的请求获取数据的方式不同于 <code>GET</code>，<code>POST</code> 请求数据必须构建请求头才可以。<br><code>Form Data</code> 中的请求参数如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-10.gif" alt="The First Title Picture"></p>
<p>将其复制并构建一个新字典：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">From_data=&#123;<span class="string">'i'</span>:<span class="string">'我愛中國'</span>,<span class="string">'from'</span>:<span class="string">'zh-CHS'</span>,<span class="string">'to'</span>:<span class="string">'en'</span>,<span class="string">'smartresult'</span>:<span class="string">'dict'</span>,<span class="string">'client'</span>:<span class="string">'fanyideskweb'</span>,<span class="string">'salt'</span>:<span class="string">'15477056211258'</span>,<span class="string">'sign'</span>:<span class="string">'b3589f32c38bc9e3876a570b8a992604'</span>,<span class="string">'ts'</span>:<span class="string">'1547705621125'</span>,<span class="string">'bv'</span>:<span class="string">'b33a2f3f9d09bde064c9275bcb33d94e'</span>,<span class="string">'doctype'</span>:<span class="string">'json'</span>,<span class="string">'version'</span>:<span class="string">'2.1'</span>,<span class="string">'keyfrom'</span>:<span class="string">'fanyi.web'</span>,<span class="string">'action'</span>:<span class="string">'FY_BY_REALTIME'</span>,<span class="string">'typoResult'</span>:<span class="string">'false'</span>&#125;</span><br></pre></td></tr></table></figure>
<p>接下来使用 <code>requests.post</code> 方法请求表单数据，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests            <span class="comment">#导入requests包</span></span><br><span class="line">response = requests.post(url,data=payload)</span><br></pre></td></tr></table></figure>
<p>将字符串格式的数据转换成<code>JSON</code> 格式数据，并根据数据结构，提取数据，并将翻译结果打印出来，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> json</span><br><span class="line">content = json.loads(response.text)</span><br><span class="line">print(content[<span class="string">'translateResult'</span>][<span class="number">0</span>][<span class="number">0</span>][<span class="string">'tgt'</span>])</span><br></pre></td></tr></table></figure>
<p>使用 <code>requests.post</code> 方法抓取有道翻译结果的完整代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests        <span class="comment">#导入requests包</span></span><br><span class="line"><span class="keyword">import</span> json</span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_translate_date</span><span class="params">(word=None)</span>:</span></span><br><span class="line">    url = <span class="string">'http://fanyi.youdao.com/translate_o?smartresult=dict&amp;smartresult=rule'</span></span><br><span class="line">    From_data=&#123;<span class="string">'i'</span>:word,<span class="string">'from'</span>:<span class="string">'zh-		    CHS'</span>,<span class="string">'to'</span>:<span class="string">'en'</span>,<span class="string">'smartresult'</span>:<span class="string">'dict'</span>,<span class="string">'client'</span>:<span class="string">'fanyideskweb'</span>,<span class="string">'salt'</span>:<span class="string">'15477056211258'</span>,<span class="string">'sign'</span>:<span class="string">'b3589f32c38bc9e3876a570b8a992604'</span>,<span class="string">'ts'</span>:<span class="string">'1547705621125'</span>,<span class="string">'bv'</span>:<span class="string">'b33a2f3f9d09bde064c9275bcb33d94e'</span>,<span class="string">'doctype'</span>:<span class="string">'json'</span>,<span class="string">'version'</span>:<span class="string">'2.1'</span>,<span class="string">'keyfrom'</span>:<span class="string">'fanyi.web'</span>,<span class="string">'action'</span>:<span class="string">'FY_BY_REALTIME'</span>,<span class="string">'typoResult'</span>:<span class="string">'false'</span>&#125;</span><br><span class="line">    <span class="comment">#请求表单数据</span></span><br><span class="line">    response = requests.post(url,data=From_data)</span><br><span class="line">    <span class="comment">#将Json格式字符串转字典</span></span><br><span class="line">    content = json.loads(response.text)</span><br><span class="line">    print(content)</span><br><span class="line">    <span class="comment">#打印翻译后的数据</span></span><br><span class="line">    <span class="comment">#print(content['translateResult'][0][0]['tgt'])</span></span><br><span class="line"><span class="keyword">if</span> __name__==<span class="string">'__main__'</span>:</span><br><span class="line">    get_translate_date(<span class="string">'我爱中国'</span>)</span><br></pre></td></tr></table></figure>
<h1 id="3-使用-Beautiful-Soup-解析网页"><a href="#3-使用-Beautiful-Soup-解析网页" class="headerlink" title="3 使用 Beautiful Soup 解析网页"></a>3 使用 Beautiful Soup 解析网页</h1><p>通过 <code>requests</code> 库已经可以抓到网页源码，接下来要从源码中找到并提取数据。<code>Beautiful Soup</code> 是 <code>python</code> 的一个库，其最主要的功能是从网页中抓取数据。<code>Beautiful Soup</code> 目前已经被移植到 <code>bs4</code> 库中，也就是说在导入 <code>Beautiful Soup</code> 时需要先安装<code>bs4</code> 库。</p>
<p>终端直接输入<code>pip3 install beautifulsoup4</code>安装。</p>
<p>安装好 <code>bs4</code> 库以后，还需安装<code>lxml</code> 库。如果我们不安装 <code>lxml</code>库，就会使用 <code>Python</code> 默认的解析器。尽管 <code>Beautiful Soup</code>既支持<code>Python</code> 标准库中的<code>HTML</code>解析器又支持一些第三方解析器，但是 <code>lxml</code> 库具有功能更加强大、速度更快的特点，因此笔者推荐安装<code>lxml</code>库。</p>
<p>安装 <code>Python</code>第三方库后，输入下面的代码，即可开启<code>Beautiful Soup</code>之旅：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">import</span> requests                           <span class="comment">#导入requests包</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line">url=<span class="string">'http://www.cntour.cn/'</span></span><br><span class="line">strhtml=requests.get(url)</span><br><span class="line">soup=BeautifulSoup(strhtml.text,<span class="string">'lxml'</span>)</span><br><span class="line">data = soup.select(<span class="string">'#main&gt;div&gt;div.mtop.firstMod.clearfix&gt;div.centerBox&gt;ul.newsList&gt;li&gt;a'</span>)</span><br><span class="line">print(data)</span><br></pre></td></tr></table></figure>
<p><code>Beautiful Soup</code> 库能够轻松解析网页信息，它被集成在 <code>bs4</code> 库中，需要时可以从 <code>bs4</code> 库中调用。其表达语句如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br></pre></td></tr></table></figure>
<p>首先，<code>HTML</code> 文档将被转换成 <code>Unicode</code> 编码格式，然后 <code>Beautiful Soup</code> 选择最合适的解析器来解析这段文档，此处指定 <code>lxml</code>解析器进行解析。解析后便将复杂的 <code>HTML</code> 文档转换成树形结构，并且每个节点都是 <code>Python</code> 对象。这里将解析后的文档存储到新建的变量 <code>soup</code> 中，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">soup=BeautifulSoup(strhtml.text,<span class="string">'lxml'</span>)</span><br></pre></td></tr></table></figure>
<p>接下来用 <code>select</code>（选择器）定位数据，定位数据时需要使用浏览器的开发者模式，将鼠标光标停留在对应的数据位置并右击，然后在快捷菜单中选择<code>检查</code>命令，如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-11.gif" alt="The First Title Picture"></p>
<p>随后在浏览器右侧会弹出开发者界面，右侧高亮的代码（下图(b)）对应着左侧高亮的数据文本（下图(a)）。右击右侧高亮数据，在弹出的快捷菜单中选择<code>“Copy”➔“Copy Selector”</code>命令，便可以自动复制路径。</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-12.gif" alt="The First Title Picture"></p>
<p>将路径粘贴在文档中，代码如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#main &gt; div &gt; div.mtop.firstMod.clearfix &gt; div.centerBox &gt; ul.newsList &gt; li:nth-child(1) &gt; a</span><br></pre></td></tr></table></figure>
<p>由于这条路径是选中的第一条的路径，而我们需要获取所有的头条新闻，因此将 <code>li：nth-child（1）</code>中冒号（包含冒号）后面的部分删掉，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">#main &gt; div &gt; div.mtop.firstMod.clearfix &gt; div.centerBox &gt; ul.newsList &gt; li &gt; a</span><br></pre></td></tr></table></figure>
<p>使用 <code>soup.select</code> 引用这个路径，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">data &#x3D; soup.select(&#39;#main &gt; div &gt; div.mtop.firstMod.clearfix &gt; div.centerBox &gt; ul.newsList &gt; li &gt; a&#39;)</span><br></pre></td></tr></table></figure>
<h1 id="4-清洗和组织数据"><a href="#4-清洗和组织数据" class="headerlink" title="4 清洗和组织数据"></a>4 清洗和组织数据</h1><p>至此，获得了一段目标的 <code>HTML</code>代码，但还没有把数据提取出来，输入以下代码：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">for item in data:</span><br><span class="line">    result&#x3D;&#123;</span><br><span class="line">        &#39;title&#39;:item.get_text(),</span><br><span class="line">        &#39;link&#39;:item.get(&#39;href&#39;)</span><br><span class="line">    &#125;</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<p>代码运行结果如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-15.jpg" alt="The First Title Picture"></p>
<p>首先明确要提取的数据是标题和链接，标题在<code>＜a＞</code>标签中，提取标签的正文用 <code>get_text()</code> 方法。链接在<code>＜a＞</code>标签的<code>href</code>属性中，提取标签中的<code>href</code>属性用 <code>get()</code>方法，在括号中指定要提取的属性数据，即<code>get(＇href＇)</code>。</p>
<p>从上图中可以发现，文章的链接中有一个数字 ID。下面用正则表达式提取这个 ID。需要使用的正则符号如下:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">\d匹配数字</span><br><span class="line">+匹配前一个字符1次或多次</span><br></pre></td></tr></table></figure>
<p>在 Python 中调用正则表达式时使用 <code>re</code> 库，这个库不用安装，可以直接调用。输入以下代码:</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br></pre></td><td class="code"><pre><span class="line">import re</span><br><span class="line">for item in data:</span><br><span class="line">    result&#x3D;&#123;</span><br><span class="line">        &quot;title&quot;:item.get_text(),</span><br><span class="line">        &quot;link&quot;:item.get(&#39;href&#39;),</span><br><span class="line">        &#39;ID&#39;:re.findall(&#39;\d+&#39;,item.get(&#39;href&#39;))</span><br><span class="line">    &#125;</span><br><span class="line">print(result)</span><br></pre></td></tr></table></figure>
<p>运行结果如下图所示：</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-14.jpg" alt="The First Title Picture"></p>
<p>这里使用 <code>re</code> 库的 <code>findall</code> 方法，第一个参数表示正则表达式，第二个参数表示要提取的文本。</p>
<h1 id="5-爬虫攻防战"><a href="#5-爬虫攻防战" class="headerlink" title="5 爬虫攻防战"></a>5 爬虫攻防战</h1><p>爬虫是模拟人的浏览访问行为，进行数据的批量抓取。当抓取的数据量逐渐增大时，会给被访问的服务器造成很大的压力，甚至有可能崩溃。换句话就是说，服务器是不喜欢有人抓取自己的数据的。那么，网站方面就会针对这些爬虫者，采取一些反爬策略。</p>
<p>服务器第一种识别爬虫的方式就是通过检查连接的 <code>useragent</code> 来识别到底是浏览器访问，还是代码访问的。如果是代码访问的话，访问量增大时，服务器会直接封掉来访 IP。</p>
<p>那么应对这种初级的反爬机制，我们应该采取何种举措？</p>
<p>还是以前面创建好的爬虫为例。在进行访问时，我们在开发者环境下不仅可以找到 <code>URL</code>、<code>Form Data</code>，还可以在 <code>Request headers</code> 中构造浏览器的请求头，封装自己。服务器识别浏览器访问的方法就是判断 <code>keyword</code> 是否为 <code>Request headers</code> 下的 <code>User-Agent</code>，如所示。</p>
<p><img src="/2019/05/20/Py190520-%E5%86%99%E4%B8%80%E4%B8%AA%E6%9C%80%E7%AE%80%E5%8D%95%E7%9A%84%E7%88%AC%E8%99%AB%E7%A8%8B%E5%BA%8F/190520-13.jpg" alt="The First Title Picture"></p>
<p>因此，我们只需要构造这个请求头的参数。创建请求头部信息即可，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">headers&#x3D;&#123;&#39;User-Agent&#39;:&#39;Mozilla&#x2F;5.0 (Windows NT 10.0; Win64; x64) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;70.0.3538.110 Safari&#x2F;537.36&#39;&#125;</span><br><span class="line">response &#x3D; request.get(url,headers&#x3D;headers)</span><br></pre></td></tr></table></figure>
<p>在实际操作中加了头部信息之后，还是会出现<code>urllib.error.HTTPError: HTTP Error 403: Forbidden</code>的问题，开审查元素，到Network界面刷新，发现图片加载时有<code>Referer</code>的<code>header</code>，加上<code>Referer</code>之后，问题解决。</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">opener&#x3D;urllib.request.build_opener()</span><br><span class="line">opener.addheaders&#x3D;[(&#39;User-Agent&#39;,&#39;Mozilla&#x2F;5.0 (Macintosh; Intel Mac OS X 10_14_6) AppleWebKit&#x2F;537.36 (KHTML, like Gecko) Chrome&#x2F;90.0.4430.93 Safari&#x2F;537.36&#39;),(&#39;Referer&#39;,m_url)]</span><br><span class="line">urllib.request.install_opener(opener)</span><br></pre></td></tr></table></figure>
<p>写到这里，很多读者会认为修改 <code>User-Agent</code> 很太简单。确实很简单，但是正常人1秒看一个图，而个爬虫1秒可以抓取好多张图，比如 1 秒抓取上百张图，那么服务器的压力必然会增大。也就是说，如果在一个 IP 下批量访问下载图片，这个行为不符合正常人类的行为，肯定要被封 IP。</p>
<p>其原理也很简单，就是统计每个IP的访问频率，该频率超过阈值，就会返回一个验证码，如果真的是用户访问的话，用户就会填写，然后继续访问，如果是代码访问的话，就会被封 IP。</p>
<p>这个问题的解决方案有两个，第一个就是常用的增设延时，每 3 秒钟抓取一次，代码如下：</p>
<figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">import time</span><br><span class="line">time.sleep(3)</span><br></pre></td></tr></table></figure>
<p>但是，我们写爬虫的目的是为了高效批量抓取数据，这里设置 3 秒钟抓取一次，效率未免太低。其实，还有一个更重要的解决办法，那就是从本质上解决问题。</p>
<p>不管如何访问，服务器的目的就是查出哪些为代码访问，然后封锁 IP。解决办法：为避免被封 IP，在数据采集时经常会使用代理。当然，<code>requests</code> 也有相应的 <code>proxies</code>属性。</p>
<p>首先，构建自己的代理 IP 池，将其以字典的形式赋值给 <code>proxies</code>，然后传输给 <code>requests</code>，代码如下：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">proxies=&#123;</span><br><span class="line">    <span class="string">"http"</span>:<span class="string">"http://10.10.1.10:3128"</span>,</span><br><span class="line">    <span class="string">"https"</span>:<span class="string">"http://10.10.1.10:1080"</span>,</span><br><span class="line">&#125;</span><br><span class="line">response = requests.get(url, proxies=proxies)</span><br></pre></td></tr></table></figure>
<p>下面为一段实际抓取图片的代码供参考：</p>
<figure class="highlight python"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment">#coding=utf-8</span></span><br><span class="line"><span class="keyword">import</span> requests        <span class="comment">#导入requests包</span></span><br><span class="line"><span class="keyword">from</span> bs4 <span class="keyword">import</span> BeautifulSoup</span><br><span class="line"><span class="keyword">import</span> time</span><br><span class="line"><span class="keyword">import</span> re</span><br><span class="line"><span class="keyword">import</span> urllib.request</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">get_img</span><span class="params">(m_url,pic_name)</span>:</span></span><br><span class="line">    strhtml = requests.get(url=m_url)               <span class="comment">#Get方式获取网页数据</span></span><br><span class="line">    soup=BeautifulSoup(strhtml.text,<span class="string">'lxml'</span>)</span><br><span class="line">    data = soup.select(<span class="string">'xxxxx'</span>)                     <span class="comment">#用BeautifulSoup清晰数据</span></span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> item <span class="keyword">in</span> data:</span><br><span class="line">        result = &#123;<span class="string">'link'</span>:item.get(<span class="string">'src'</span>),<span class="string">'title'</span>:item.get(<span class="string">'title'</span>)&#125;     <span class="comment">#提取元素</span></span><br><span class="line">    img_url = result[<span class="string">'link'</span>]                                            <span class="comment">#获取图片链接</span></span><br><span class="line">    img_name = pic_name + <span class="string">' '</span> + result[<span class="string">'title'</span>] + <span class="string">'.jpg'</span>                <span class="comment">#获取图片的名字</span></span><br><span class="line"></span><br><span class="line">    </span><br><span class="line">    opener=urllib.request.build_opener()</span><br><span class="line">    opener.addheaders=[(<span class="string">'User-Agent'</span>,<span class="string">'Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/70.0.3538.110 Safari/537.36'</span>),(<span class="string">'Referer'</span>,m_url)]</span><br><span class="line">    urllib.request.install_opener(opener)</span><br><span class="line">    urllib.request.urlretrieve(img_url,<span class="string">'下载路径'</span>)</span><br><span class="line">    print(<span class="string">'成功下载'</span>+img_name)</span><br><span class="line"></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">main</span><span class="params">()</span>:</span></span><br><span class="line">    m_url = <span class="string">'xxxxx'</span> </span><br><span class="line">    pic_name = <span class="string">'xxxxx'</span></span><br><span class="line">    get_img(m_url,pic_name)</span><br><span class="line">    time.sleep(<span class="number">5</span>)                  <span class="comment">#程序停顿5秒，此处即可实现批量化程序</span></span><br><span class="line">    </span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    main()</span><br></pre></td></tr></table></figure>
<h1 id="6-其他"><a href="#6-其他" class="headerlink" title="6 其他"></a>6 其他</h1><p>此文大量参照此<a href="http://c.biancheng.net/view/2011.html" target="_blank" rel="noopener">博客内容</a>，并加入自己的内容以及内容抓取相关介绍。</p>

                
                <hr>
                <!-- Pager -->
                <!-- Here is the place to change the preview?????no  -->
                <ul class="pager">

                    
                    <li class="previous">
                        <a href="/2019/09/18/Cpp190918-macOS上使用VScode编译配置C-语言开发环境/" data-toggle="tooltip" data-placement="top" title="macOS上使用VScode编译配置C++语言开发环境">&larr; Previous Post</a>
                    </li>
                    

                    
                    <li class="next">
                        <a href="/2019/01/01/Blog190101-Life-Goals/" data-toggle="tooltip" data-placement="top" title="很喜欢的一句话">Next Post &rarr;</a>
                    </li>
                    

                </ul>

                <!-- tip start -->
                

                
                <!-- tip end -->

                <!-- Music start-->
                
                

<link rel="stylesheet" href="/css/music-player/fonts/iconfont.css">


<link rel="stylesheet" href="/css/music-player/css/reset.css">


<link rel="stylesheet" href="/css/music-player/css/player.css">



<div class="music-player">
    <audio class="music-player__audio" ></audio>
    <div class="music-player__main">
        <div class="music-player__blur"></div>
        <div class="music-player__disc">
            <div class="music-player__image">
                <img width="100%" src="" alt="">
            </div>
            <div class="music-player__pointer"><img width="100%" src="/img/cd_tou.png" alt=""></div>
        </div>
        <div class="music-player__controls">
            <div class="music__info">
                <h3 class="music__info--title">...</h3>
                <p class="music__info--singer">...</p>
            </div>
            <div class="player-control">
                <div class="player-control__content">
                    <div class="player-control__btns">
                        <div class="player-control__btn player-control__btn--prev"><i class="iconfont icon-prev"></i></div>
                        <div class="player-control__btn player-control__btn--play"><i class="iconfont icon-play"></i></div>
                        <div class="player-control__btn player-control__btn--next"><i class="iconfont icon-next"></i></div>
                        <div class="player-control__btn player-control__btn--mode"><i class="iconfont icon-loop"></i></div>
                    </div>
                    <div class="player-control__volume">
                        <div class="control__volume--icon player-control__btn"><i class="iconfont icon-volume"></i></div>
                        <div class="control__volume--progress player_progress"></div>
                    </div>
                </div>
                <div class="player-control__content">
                    <div class="player__song--progress player_progress"></div>
                    <div class="player__song--timeProgess nowTime">00:00</div>
                    <div class="player__song--timeProgess totalTime">00:00</div>
                </div>

            </div>

        </div>
    </div>
</div>


<script src="/js/music-player/utill.js"></script>


<script src="/js/music-player/jquery.min.js"></script>


<script src="/js/music-player/player.js"></script>


                
                <!-- Music end -->

                <!-- Sharing -->
                
                <!-- Sharing -->

                <!-- gitment start -->
                
                <!-- gitment end -->

                <!-- 来必力City版安装代码 -->
                
                <!-- City版安装代码已完成 -->

                <!-- disqus comment start -->
                
                <!-- disqus comment end -->
            </div>
            
            <!-- Tabe of Content -->
            <!-- Table of Contents -->

    
      <aside id="sidebar">
        <div id="toc" class="toc-article">
        <strong class="toc-title">Contents</strong>
        
          <ol class="toc-nav"><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#1-网页基础"><span class="toc-nav-text">1 网页基础</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-1-网页结构"><span class="toc-nav-text">1.1 网页结构</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-2-写一个简单的-HTML"><span class="toc-nav-text">1.2 写一个简单的 HTML</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#1-3-关于爬虫的合法性"><span class="toc-nav-text">1.3 关于爬虫的合法性</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#2-使用-requests-库请求网站"><span class="toc-nav-text">2 使用 requests 库请求网站</span></a><ol class="toc-nav-child"><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-1-安装-requests-库"><span class="toc-nav-text">2.1 安装 requests 库</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-2-爬虫的基本原理"><span class="toc-nav-text">2.2 爬虫的基本原理</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-3-网页请求方式一：使用-GET-方式抓取数据"><span class="toc-nav-text">2.3 网页请求方式一：使用 GET 方式抓取数据</span></a></li><li class="toc-nav-item toc-nav-level-2"><a class="toc-nav-link" href="#2-4-网页请求方式二：使用-POST-方式抓取数据"><span class="toc-nav-text">2.4 网页请求方式二：使用 POST 方式抓取数据</span></a></li></ol></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#3-使用-Beautiful-Soup-解析网页"><span class="toc-nav-text">3 使用 Beautiful Soup 解析网页</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#4-清洗和组织数据"><span class="toc-nav-text">4 清洗和组织数据</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#5-爬虫攻防战"><span class="toc-nav-text">5 爬虫攻防战</span></a></li><li class="toc-nav-item toc-nav-level-1"><a class="toc-nav-link" href="#6-其他"><span class="toc-nav-text">6 其他</span></a></li></ol>
        
        </div>
      </aside>
    

                
            <!-- Sidebar Container -->
            <div class="
                col-lg-8 col-lg-offset-2
                col-md-10 col-md-offset-1
                sidebar-container">

                <!-- Featured Tags -->
                
                <section>
                    <!-- no hr -->
                    <h5><a href="/tags/">FEATURED TAGS</a></h5>
                    <div class="tags">
                       
                          <a class="tag" href="/tags/#Python" title="Python">Python</a>
                        
                          <a class="tag" href="/tags/#Web Crawler" title="Web Crawler">Web Crawler</a>
                        
                    </div>
                </section>
                

                <!-- Friends Blog -->
                
                <hr>
                <h5>LINKS</h5>
                <ul class="list-inline">

                    
                        <li><a href="#" target="_blank">Zhihao&#39;s Blog</a></li>
                    
                        <li><a href="#" target="_blank">HomePage</a></li>
                    
                        <li><a href="#" target="_blank">Other</a></li>
                    
                </ul>
                
            </div>
        </div>
    </div>
</article>




<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>
<!-- anchor-js, Doc:http://bryanbraun.github.io/anchorjs/ -->
<script>
    async("https://cdn.bootcss.com/anchor-js/1.1.1/anchor.min.js",function(){
        anchors.options = {
          visible: 'hover',
          placement: 'left',
          icon: 'ℬ'
        };
        anchors.add().remove('.intro-header h1').remove('.subheading').remove('.sidebar-container h5');
    })
</script>


<style  type="text/css">
    /* place left on bigger screen */
    @media all and (min-width: 800px) {
        .anchorjs-link{
            position: absolute;
            left: -0.75em;
            font-size: 1.1em;
            margin-top : -0.1em;
        }
    }
</style>



    <!-- Footer -->
    <!-- Footer -->
<!-- 主页底部在这里修改 -->
<footer>
    <div class="container">
        <div class="row">
            <div class="col-lg-8 col-lg-offset-2 col-md-10 col-md-offset-1">
                <ul class="list-inline text-center">

                

                

                

                

                

                

                

                </ul>
                <p class="copyright text-muted">
                    &copy; 2017-2023 YaoZhihao
                    <!-- 原代码 Copyright &copy; Zhihao 2023 -->
                    <br>
                    Theme by Snail <i class="fa fa-heart" aria-hidden="true"></i> Ported by <a href="https://yaozhihao.com" target="_blank" rel="noopener"> YaoZhihao </a>
                    <!-- Powered by Hexo | Theme by <a href="https://yaozhihao.com" target="_blank" rel="noopener"> Nail </a> -->
                    <!-- Note: to improve web accessibility, we recommend using aria-hidden="true" to hide icons used purely for decoration. -->
                    <!-- 原代码 去掉竖线及后面的GitHub引用数量 以下注释内部为原代码-->
                    <!-- <iframe style="margin-left: 2px; margin-bottom:-5px;" frameborder="0" scrolling="0" -->
                    <!-- width="100px" height="20px" -->
                    <!-- src="https://ghbtns.com/github-btn.html?user=dusign&repo=hexo-theme-snail&type=star&count=true"> -->
                    <!-- </iframe> -->    
                    
                </p>
            </div>
        </div>
    </div>

</footer>

<!-- jQuery -->

<script src="/js/jquery.min.js"></script>


<!-- Bootstrap Core JavaScript -->

<script src="/js/bootstrap.min.js"></script>


<!-- Custom Theme JavaScript -->

<script src="/js/hux-blog.min.js"></script>


<!-- Search -->

<script src="/js/search.js"></script>


<!-- async load function -->
<script>
    function async(u, c) {
      var d = document, t = 'script',
          o = d.createElement(t),
          s = d.getElementsByTagName(t)[0];
      o.src = u;
      if (c) { o.addEventListener('load', function (e) { c(null, e); }, false); }
      s.parentNode.insertBefore(o, s);
    }
</script>


<!-- jquery.tagcloud.js -->
<script>
    // only load tagcloud.js in tag.html
    if($('#tag_cloud').length !== 0){
        async("http://ningmoon.github.io/js/jquery.tagcloud.js",function(){
            $.fn.tagcloud.defaults = {
                //size: {start: 1, end: 1, unit: 'em'},
                color: {start: '#bbbbee', end: '#0085a1'},
            };
            $('#tag_cloud a').tagcloud();
        })
    }
</script>

<!--fastClick.js -->
<script>
    async("https://cdn.bootcss.com/fastclick/1.0.6/fastclick.min.js", function(){
        var $nav = document.querySelector("nav");
        if($nav) FastClick.attach($nav);
    })
</script>


<!-- Google Analytics -->


<script>
    // dynamic User by Hux
    var _gaId = 'UA-XXXXXXXX-X';
    var _gaDomain = 'yoursite';

    // Originial
    (function(i,s,o,g,r,a,m){i['GoogleAnalyticsObject']=r;i[r]=i[r]||function(){
    (i[r].q=i[r].q||[]).push(arguments)},i[r].l=1*new Date();a=s.createElement(o),
    m=s.getElementsByTagName(o)[0];a.async=1;a.src=g;m.parentNode.insertBefore(a,m)
    })(window,document,'script','//www.google-analytics.com/analytics.js','ga');

    ga('create', _gaId, _gaDomain);
    ga('send', 'pageview');
</script>




<!-- Baidu Tongji -->


<!-- Search -->

    <script type="text/javascript">      
        var search_path = "search.xml";
        if (search_path.length == 0) {
            search_path = "search.xml";
        }
    var path = "/" + search_path;
    searchFunc(path, 'local-search-input', 'local-search-result');
    </script>


<!-- busuanzi -->
<!-- hide 20200310 -->
<!-- <script async src="//busuanzi.ibruce.info/busuanzi/2.3/busuanzi.pure.mini.js"></script> -->







	<a id="rocket" href="#top" class=""></a>
	<script type="text/javascript" src="/js/totop.js?v=1.0.0" async=""></script>
    <script type="text/javascript" src="/js/toc.js?v=1.0.0" async=""></script>

    
        <!-- background effects line -->
        

        

        <!-- background effects end -->
    

    <!--<script size="50" alpha='0.3' zIndex="-999" src="/js/ribbonStatic.js"></script>-->
    
        <script src="/js/ribbonDynamic.js"></script>
    
<script type="text/x-mathjax-config">
    MathJax.Hub.Config({
        tex2jax: {
            inlineMath: [ ["$","$"], ["\\(","\\)"] ],
            skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code'],
            processEscapes: true
        }
    });
    MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax();
        for (var i = 0; i < all.length; ++i)
            all[i].SourceElement().parentNode.className += ' has-jax';
    });
</script>
<script src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.6/MathJax.js?config=TeX-MML-AM_CHTML"></script>

</body>

</html>
